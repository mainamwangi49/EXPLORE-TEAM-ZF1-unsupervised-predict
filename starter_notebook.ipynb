{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-07T18:23:28.213402Z","iopub.execute_input":"2022-07-07T18:23:28.213762Z","iopub.status.idle":"2022-07-07T18:23:28.223768Z","shell.execute_reply.started":"2022-07-07T18:23:28.213733Z","shell.execute_reply":"2022-07-07T18:23:28.222632Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Installing packages","metadata":{}},{"cell_type":"code","source":"# Install packages here\n# Packages for data processing\nimport numpy as np\nimport pandas as pd\nimport datetime\nfrom sklearn import preprocessing\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport re\nfrom scipy.sparse import csr_matrix\nimport scipy as sp\n\n\n# Packages for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Packages for modeling\nfrom surprise import Reader\nfrom surprise import Dataset\nfrom surprise import KNNWithMeans\nfrom surprise import KNNBasic\nfrom surprise.model_selection import GridSearchCV\nfrom surprise.model_selection import cross_validate, train_test_split\nfrom surprise import SVD,accuracy\nfrom surprise import SVDpp\nfrom surprise import NMF\nfrom surprise import SlopeOne\nfrom surprise import CoClustering\nimport heapq\n\n# Packages for model evaluation\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom time import time\n\n# Package to suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Packages for saving models\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:30:04.984410Z","iopub.execute_input":"2022-07-07T18:30:04.984735Z","iopub.status.idle":"2022-07-07T18:30:04.997609Z","shell.execute_reply.started":"2022-07-07T18:30:04.984711Z","shell.execute_reply":"2022-07-07T18:30:04.996289Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Reading in data","metadata":{}},{"cell_type":"code","source":"df_sample_submission = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/sample_submission.csv')\ndf_movies = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/movies.csv')\ndf_imdb = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/imdb_data.csv')\ndf_genome_scores = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/genome_scores.csv')\ndf_genome_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/genome_tags.csv')\ndf_train = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/train.csv')\ndf_test = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/test.csv')\ndf_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/tags.csv')\ndf_links = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/links.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:25:27.351323Z","iopub.execute_input":"2022-07-07T18:25:27.351750Z","iopub.status.idle":"2022-07-07T18:25:53.216616Z","shell.execute_reply.started":"2022-07-07T18:25:27.351720Z","shell.execute_reply":"2022-07-07T18:25:53.215199Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"**Most common Genres**","metadata":{}},{"cell_type":"code","source":"# Create dataframe containing only the movieId and genres\nmovies_genres = pd.DataFrame(df_movies[['movieId', 'genres']],\n                             columns=['movieId', 'genres'])\n\n# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\nmovies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n\n# Create expanded dataframe where each movie-genre combination is in a seperate row\nmovies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n                             columns=['movieId', 'genres'])\n\nmovies_genres.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:26:44.315342Z","iopub.execute_input":"2022-07-07T18:26:44.315721Z","iopub.status.idle":"2022-07-07T18:26:44.976148Z","shell.execute_reply.started":"2022-07-07T18:26:44.315693Z","shell.execute_reply":"2022-07-07T18:26:44.975008Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Plot the genres from most common to least common\nplot = plt.figure(figsize=(15, 10))\nplt.title('Most common genres\\n', fontsize=20)\nsns.countplot(y=\"genres\", data=movies_genres,\n              order=movies_genres['genres'].value_counts(ascending=False).index,\n              palette='tab10')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:28:05.013654Z","iopub.execute_input":"2022-07-07T18:28:05.014708Z","iopub.status.idle":"2022-07-07T18:28:05.425470Z","shell.execute_reply.started":"2022-07-07T18:28:05.014675Z","shell.execute_reply":"2022-07-07T18:28:05.424412Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Ratings distribution","metadata":{}},{"cell_type":"code","source":"from plotly.offline import init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\ndata = df_train['rating'].value_counts().sort_index(ascending=False)\ntrace = go.Bar(x = data.index,\n               text = ['{:.1f} %'.format(val) for val in \n                       (data.values / df_train.shape[0] * 100)],\n               textposition = 'auto',\n               textfont = dict(color = '#000000'),\n               y = data.values,\n               )\n# Create layout\nlayout = dict(title = 'Distribution of movie ratings'.format(df_train.shape[0]),\n              xaxis = dict(title = 'Rating'),\n              yaxis = dict(title = 'Count'))\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:32:42.317246Z","iopub.execute_input":"2022-07-07T18:32:42.318179Z","iopub.status.idle":"2022-07-07T18:32:42.500179Z","shell.execute_reply.started":"2022-07-07T18:32:42.318131Z","shell.execute_reply":"2022-07-07T18:32:42.499068Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Number of ratings per movie\ndata = df_train.groupby('movieId')['rating'].count().clip(upper=50)\n\n# Create trace\ntrace = go.Histogram(x = data.values,\n                     name = 'Ratings',\n                     xbins = dict(start = 0,\n                                  end = 50,\n                                  size = 2))\n# Create layout\nlayout = go.Layout(title = 'Distribution of Number of Ratings Per Movie',\n                   xaxis = dict(title = 'Number of Ratings Per movie'),\n                   yaxis = dict(title = 'Count'),\n                   bargap = 0.2)\n\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:36:46.350095Z","iopub.execute_input":"2022-07-07T18:36:46.350426Z","iopub.status.idle":"2022-07-07T18:36:46.719649Z","shell.execute_reply.started":"2022-07-07T18:36:46.350401Z","shell.execute_reply":"2022-07-07T18:36:46.718689Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df_train.groupby('userId')['rating'].count().reset_index().sort_values(\n    'rating', ascending=False)[:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:35:07.567097Z","iopub.execute_input":"2022-07-07T18:35:07.567576Z","iopub.status.idle":"2022-07-07T18:35:07.983488Z","shell.execute_reply.started":"2022-07-07T18:35:07.567537Z","shell.execute_reply":"2022-07-07T18:35:07.981645Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Modelling \n\nIn this section the models to be used in building the recommender system will be explored. They will incude both Content based or Collabrative methods.","metadata":{}},{"cell_type":"code","source":"data = Dataset.load_from_df(df_train[['userId', 'movieId', 'rating']], Reader())","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:41:35.568540Z","iopub.execute_input":"2022-07-07T18:41:35.568910Z","iopub.status.idle":"2022-07-07T18:41:52.355914Z","shell.execute_reply.started":"2022-07-07T18:41:35.568881Z","shell.execute_reply":"2022-07-07T18:41:52.354953Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_set, test_set = train_test_split(data, test_size=0.20)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:41:59.608974Z","iopub.execute_input":"2022-07-07T18:41:59.609902Z","iopub.status.idle":"2022-07-07T18:42:38.645538Z","shell.execute_reply.started":"2022-07-07T18:41:59.609864Z","shell.execute_reply":"2022-07-07T18:42:38.644412Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"svd=SVD(n_epochs = 30, n_factors = 200, init_std_dev = 0.05, random_state=42)\nsvd.fit(train_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions\ntest_pred= svd.test(test_set)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate model performance\nrsme_collabo = accuracy.rmse(test_pred,verbose=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting the rating for each user and movie\nratings=[]\nfor x,y in df_test.itertuples(index=False):\n    output=svd.predict(x,y)\n    ratings.append(output)\n    \noutput_df=pd.DataFrame(ratings)[['uid','iid','est']]\noutput_df['ID']=output_df['uid'].astype(str) + '_' + output_df['iid'].astype(str)\noutput_df=output_df[['ID','est']]\noutput_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create submission file","metadata":{}},{"cell_type":"code","source":"#Creating the \"results\" dataframe and convert to csv\nresults = pd.DataFrame({\"Id\":output_df['ID'],\"rating\": output_df['est']})\nresults.to_csv(\"SVD.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': results.Id, 'rating': results.rating})\nsubmission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}